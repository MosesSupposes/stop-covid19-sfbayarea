name: news.json update

on:
  schedule:
    # Run every 3 hours
    - cron: 0 */3 * * *

jobs:
  # This workflow has only one job.
  build:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
      with:
        ssh-key: ${{ secrets.data_daily_update }}
        path: site

    # Checkout news scraper repo
    - name: Checkout Data Scraper
      uses: actions/checkout@v2
      with:
        ssh-key: ${{ secrets.data_daily_update }}
        repository: sfbrigade/data-covid19-sfbayarea
        path: scraper

    # The scraper uses Python 3.7+, so make sure we've got the latest 3.x
    - name: Set up Python 3.x
      uses: actions/setup-python@v1
      with:
        python-version: '3.x'

    # Install dependencis
    # - The commit that was checked out will be available as $SCRAPER_COMMIT.
    - name: Install Data Scraper & Dependencies
      run: |
        cd ${GITHUB_WORKSPACE}/scraper
        python -m pip install --upgrade pip
        pip install -r requirements.txt;

        # Keep track of the version used so we can use it in commit messages
        echo "::set-env name=SCRAPER_COMMIT::$(git rev-parse HEAD)"

    # Run the news scraper
    - name: Scrape News
      run: |
        echo "::set-env name=SCRAPER_TIME::$(date)"
        cd ${GITHUB_WORKSPACE}/scraper
        # TODO: stop explicitly listing every county when the scraper repo is
        # updated to scrape every county by default. (We have to do this first
        # before the scraper can update, otherwise it would break older code in
        # this repo!)
        python scraper_news.py alameda contra_costa marin napa san_francisco san_mateo santa_clara solano sonoma --format json_feed --output "${GITHUB_WORKSPACE}/site/data/news/"
    
    - name: Create PR if New Data
      uses: peter-evans/create-pull-request@v2
      with:
        path: site
        # If this branch already exists, it will be replaced with a commit
        # based on the changes from this job. If there's already a PR for it,
        # the PR will be updated. The end result is that each run of this job
        # supersedes or replaces any previous runs that haven't been reviewed
        # and merged yet.
        branch: auto-update-news
        title: 'GitHub action: news update'
        body: |
          Created using commit [${{env.SCRAPER_COMMIT}}](https://github.com/sfbrigade/data-covid19-sfbayarea/commit/${{env.SCRAPER_COMMIT}})
          from sfbrigade/data-covid19-sfbayarea.
          
          Scraped at: ${{ env.SCRAPER_TIME }}
        commit-message: |
          GitHubAction: news update
          
          Created with commit ${{env.SCRAPER_COMMIT}} from sfbrigade/data-covid19-sfbayarea
          https://github.com/sfbrigade/data-covid19-sfbayarea/commit/${{env.SCRAPER_COMMIT}}
        reviewers: kengoy, Mr0grog
